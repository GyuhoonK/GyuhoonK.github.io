<!DOCTYPE html>
<html>
<head>
    
    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>repartition in Spark</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    </script>
<meta name="description" content="Data Engineering" />
    <link rel="shortcut icon" href="https://gyuhoonk.github.io/assets/built/images/favicon.jpg" type="image/png" />
    <link rel="canonical" href="https://gyuhoonk.github.io/spark-repartition" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Gyuhoon Kim" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="repartition in Spark" />
    <meta property="og:description" content="repartition 파헤치기 Repartition ? Spark에서 RDD, Dataset, DataFrame의 작업 최소단위는 partition입니다. 데이터에 Job을 적용할 때 Spark는 최소 단위인 partition으로 쪼개서 task을 수행합니다.하나의 executor가 하나의 task, 즉 하나의 partition에 대해 작업을 수행합니다. 이때, 해당 데이터셋(Dataset, DataFrame) 내부의 partition의 개수, 사이즈, 정렬상태는 task 수행에 영향을 줍니다. 예를 들어 아래와 같은 상황이라면 partition" />
    <meta property="og:url" content="https://gyuhoonk.github.io/spark-repartition" />
    <meta property="og:image" content="https://gyuhoonk.github.io/assets/built/images/hadoop/repartition-cover.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/" />
    <meta property="article:author" content="https://www.facebook.com/" />
    <meta property="article:published_time" content="2022-03-12T22:30:00+09:00" />
    <meta property="article:modified_time" content="2022-03-12T22:30:00+09:00" />
    <meta property="article:tag" content="Hadoop" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="repartition in Spark" />
    <meta name="twitter:description" content="repartition 파헤치기 Repartition ? Spark에서 RDD, Dataset, DataFrame의 작업 최소단위는 partition입니다. 데이터에 Job을 적용할 때 Spark는 최소 단위인 partition으로 쪼개서 task을 수행합니다.하나의 executor가 하나의 task, 즉 하나의 partition에 대해 작업을 수행합니다. 이때, 해당 데이터셋(Dataset, DataFrame) 내부의 partition의 개수, 사이즈, 정렬상태는 task 수행에 영향을 줍니다. 예를 들어 아래와 같은 상황이라면 partition" />
    <meta name="twitter:url" content="https://gyuhoonk.github.io/" />
    <meta name="twitter:image" content="https://gyuhoonk.github.io/assets/built/images/hadoop/repartition-cover.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Gyuhoon Kim" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Hadoop" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Gyuhoon Kim",
        "logo": "https://gyuhoonk.github.io/"
    },
    "url": "https://gyuhoonk.github.io/spark-repartition",
    "image": {
        "@type": "ImageObject",
        "url": "https://gyuhoonk.github.io/assets/built/images/hadoop/repartition-cover.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://gyuhoonk.github.io/spark-repartition"
    },
    "description": "repartition 파헤치기 Repartition ? Spark에서 RDD, Dataset, DataFrame의 작업 최소단위는 partition입니다. 데이터에 Job을 적용할 때 Spark는 최소 단위인 partition으로 쪼개서 task을 수행합니다.하나의 executor가 하나의 task, 즉 하나의 partition에 대해 작업을 수행합니다. 이때, 해당 데이터셋(Dataset, DataFrame) 내부의 partition의 개수, 사이즈, 정렬상태는 task 수행에 영향을 줍니다. 예를 들어 아래와 같은 상황이라면 partition"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="repartition in Spark" href="/feed.xml" />

    
</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="https://gyuhoonk.github.io/">Gyuhoon Kim</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem">
        <a href="/about/">About</a>
    </li>
    <li class="nav-python" role="menuitem">
        <a href="/tag/python/">python</a>
    </li>
    <li class="nav-scala" role="menuitem">
        <a href="/tag/scala/">scala</a>
    </li>
    <li class="nav-hadoop" role="menuitem">
        <a href="/tag/hadoop/">hadoop</a>
    </li>
    <li class="nav-database" role="menuitem">
        <a href="/tag/database/">database</a>
    </li>
    <li class="nav-database" role="menuitem">
        <a href="/tag/datascience/">DataScience</a>
    </li>
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
    <li class="nav-archive" role="menuitem">
        <a href="/author_archive.html">Tag</a>
    </li>
</ul>
        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Subscribe</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-hadoop post tag-hadoop ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="12 March 2022">12 March 2022</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/hadoop/'>HADOOP</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">repartition in Spark</h1>
            </header>

            <!-- 
            <figure class="post-full-image" style="background-image: url(/assets/built/images/hadoop/repartition-cover.jpg)">
            </figure>
             -->

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p>repartition 파헤치기</p>

<h1 id="repartition-">Repartition ?</h1>

<p>Spark에서 RDD, Dataset, DataFrame의 작업 최소단위는 partition입니다. 데이터에 Job을 적용할 때 Spark는 최소 단위인 partition으로 쪼개서 task을 수행합니다.하나의 executor가 하나의 task, 즉 하나의 partition에 대해 작업을 수행합니다.</p>

<p>이때, 해당 데이터셋(<code class="language-plaintext highlighter-rouge">Dataset</code>, <code class="language-plaintext highlighter-rouge">DataFrame</code>) 내부의 partition의 개수, 사이즈, 정렬상태는 task 수행에 영향을 줍니다. 예를 들어 아래와 같은 상황이라면 partition A를 전달받은 executor는 OOM을 피할 수 없을 것입니다.</p>

<p><img src="../../assets/built/images/hadoop/partition_example.png" alt="image" /></p>

<p>이러한 상황을 피하기 위해, partition들이 동일한 크기를 갖도록 조절(rebalancing)할 수 있는데 이를 <code class="language-plaintext highlighter-rouge">repartition</code>이라고 부릅니다. <code class="language-plaintext highlighter-rouge">repartition</code>은 필수적으로 shuffle을 동반하는 무거운 작업입니다. 따라서 <code class="language-plaintext highlighter-rouge">repartition</code>이 필요한지 심사숙고하여 적절한 수치로 적용해야합니다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">data_repartitioned</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">repartition</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">data_rdd</span> <span class="k">=</span> <span class="nv">data_repartitioned</span><span class="o">.</span><span class="py">rdd</span>
<span class="k">val</span> <span class="nv">partitions</span> <span class="k">=</span> <span class="nv">data_rdd</span><span class="o">.</span><span class="py">glom</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="nf">for</span> <span class="o">(</span><span class="n">idx</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">to</span> <span class="mi">3</span><span class="o">)</span> <span class="o">{</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition"</span><span class="o">+</span><span class="n">idx</span><span class="o">+</span> <span class="s">" has "</span><span class="o">+</span> <span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">size</span> <span class="o">+</span><span class="s">" rows"</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>partition0 has 1362 rows

partition1 has 1362 rows

partition2 has 1361 rows

partition3 has 1362 rows
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">repartition</code> 을 적용한 결과 각 partition이 같은 row 수를 갖도록 shuffle하여 각 partition에 재분배했습니다.</p>

<p><img src="../../assets/built/images/hadoop/repartition.png" alt="image" /></p>

<h1 id="repartition-by-specific-column">Repartition by Specific Column</h1>

<p>위에서 보았던 예시처럼 단순히 데이터 사이즈만 분배하는 것이 목적은 아닙니다. partition 전략을 적용할 수 있습니다. 특정 column(Key)을 기준으로 전략을 수립합니다. 전략을 적용한다는 것은 위 예시처럼 partition에 데이터를 무작위로 shuffle하는 것이 아니라 규칙에 따라 partition에 데이터를 shuffle하는 것입니다. 이러한 전략으로 hash partitoin, range partition은 Spark에서 기본으로 제공하고있고, 필요하다면 자신이 직접 전략을 만들어 적용할 수도 있습니다(custom partitioner).</p>

<p>이러한 전략을 적용하게 되면, 이후 partition 기준으로 사용된 column을 사용한 집계/조건 적용 시 쿼리 성능이 향상됩니다.</p>

<h2 id="hash-partition">Hash Partition</h2>

<p><img src="../../assets/built/images/hadoop/hash_repartition.png" alt="image" /></p>

<p>hash partition은 Key에 hash function을 적용하여 계산된 hash value가 같은 값들을 같은 partition에 분배하는 것입니다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">data_hash_repartitioned</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">repartition</span><span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="n">$</span><span class="s">"Day"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">data_rdd</span> <span class="k">=</span> <span class="nv">data_hash_repartitioned</span><span class="o">.</span><span class="py">rdd</span>
<span class="k">val</span> <span class="nv">partitions</span> <span class="k">=</span> <span class="nv">data_rdd</span><span class="o">.</span><span class="py">glom</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="nf">for</span> <span class="o">(</span><span class="n">idx</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">to</span> <span class="mi">7</span><span class="o">)</span> <span class="o">{</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition"</span><span class="o">+</span><span class="n">idx</span><span class="o">+</span> <span class="s">" has "</span><span class="o">+</span> <span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">size</span> <span class="o">+</span><span class="s">" rows"</span><span class="o">)</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition key is "</span> <span class="o">+</span> <span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">x</span><span class="o">(</span><span class="mi">2</span><span class="o">)).</span><span class="py">toSet</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>partition0 has 716 rows
partition key is Set(12, 13, 14, 18)

partition1 has 895 rows
partition key is Set(6, 9, 17, 16, 23)

partition2 has 462 rows
partition key is Set(5, 10, 31)

partition3 has 1074 rows
partition key is Set(1, 27, 7, 3, 11, 26)

partition4 has 179 rows
partition key is Set(25)

partition5 has 867 rows
partition key is Set(20, 29, 30, 19, 15)

partition6 has 717 rows
partition key is Set(2, 4, 22, 28)

partition7 has 537 rows
partition key is Set(8, 21, 24)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">data</code> 를 8개 partition으로 repartition하였습니다. 각각의 partition에 row가 몇 개나 존재하고, repartition 기준으로 사용한 column인 <code class="language-plaintext highlighter-rouge">Day</code> 값을 확인할 수 있습니다. 예를 들어, <code class="language-plaintext highlighter-rouge">partition0</code>에는 716 rows가 포함되었고, partition key로 사용된 값은 <code class="language-plaintext highlighter-rouge">12, 13, 14, 18</code>입니다. 즉,  Day 값이 <code class="language-plaintext highlighter-rouge">12, 13, 14, 18</code>인 row는 반드시 <code class="language-plaintext highlighter-rouge">partition0</code> 에 속합니다.</p>

<h2 id="range-partition">Range Partition</h2>

<p>range partition은 Key를 지정된 개수만큼의 범위로 나누고, 각각의 범위에 속하는 값을 같은 partition에 분배합니다. <code class="language-plaintext highlighter-rouge">pairRDD</code>에 <code class="language-plaintext highlighter-rouge">RangePartitioner</code>를 적용하는 방법과 <code class="language-plaintext highlighter-rouge">Dataset</code>에서 <code class="language-plaintext highlighter-rouge">repartitionByRange</code>를 이용하는 방법이 있습니다.</p>

<p><a href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/Partitioner.html"><code class="language-plaintext highlighter-rouge">Partitioner</code></a>를 이용하기 위해서는 반드시 <code class="language-plaintext highlighter-rouge">pairRDD</code>이어야만 합니다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">scala.collection.SortedSet</span>
<span class="k">def</span> <span class="nf">sortSet</span><span class="o">[</span><span class="kt">A</span><span class="o">](</span><span class="n">unsortedSet</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">A</span><span class="o">])(</span><span class="k">implicit</span> <span class="n">ordering</span><span class="k">:</span> <span class="kt">Ordering</span><span class="o">[</span><span class="kt">A</span><span class="o">])</span><span class="k">:</span> <span class="kt">SortedSet</span><span class="o">[</span><span class="kt">A</span><span class="o">]</span> <span class="k">=</span> 
    <span class="nv">SortedSet</span><span class="o">.</span><span class="py">empty</span><span class="o">[</span><span class="kt">A</span><span class="o">]</span> <span class="o">++</span> <span class="n">unsortedSet</span>

<span class="c1">// RDD</span>
<span class="k">val</span> <span class="nv">dataRDD</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">getInt</span><span class="o">(</span><span class="mi">3</span><span class="o">),</span> <span class="nv">x</span><span class="o">.</span><span class="py">getDouble</span><span class="o">(</span><span class="mi">4</span><span class="o">)))</span> <span class="c1">// key-value RDD(pair RDD)</span>
<span class="k">val</span> <span class="nv">rangePartitioner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RangePartitioner</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="n">dataRDD</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">rangedData</span> <span class="k">=</span> <span class="nv">dataRDD</span><span class="o">.</span><span class="py">partitionBy</span><span class="o">(</span><span class="n">rangePartitioner</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">partitions</span> <span class="k">=</span> <span class="nv">rangedData</span><span class="o">.</span><span class="py">glom</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="nf">for</span> <span class="o">(</span><span class="n">idx</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">to</span> <span class="mi">4</span><span class="o">)</span> <span class="o">{</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition"</span><span class="o">+</span><span class="n">idx</span><span class="o">+</span> <span class="s">" has "</span><span class="o">+</span> <span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">size</span> <span class="o">+</span><span class="s">" rows"</span><span class="o">)</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition key is "</span> <span class="o">+</span> <span class="nf">sortSet</span><span class="o">(</span><span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nv">x</span><span class="o">.</span><span class="py">_1</span><span class="o">).</span><span class="py">toSet</span><span class="o">))</span>
<span class="o">}</span>

<span class="c1">// Dataset</span>
<span class="k">val</span> <span class="nv">rangedDataset</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">repartitionByRange</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="n">$</span><span class="s">"Hour"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">rangedRDD</span> <span class="k">=</span> <span class="nv">rangedDataset</span><span class="o">.</span><span class="py">rdd</span>
<span class="k">val</span> <span class="nv">partitions</span> <span class="k">=</span> <span class="nv">rangedRDD</span><span class="o">.</span><span class="py">glom</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="nf">for</span> <span class="o">(</span><span class="n">idx</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">to</span> <span class="mi">4</span><span class="o">)</span> <span class="o">{</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition"</span><span class="o">+</span><span class="n">idx</span><span class="o">+</span> <span class="s">" has "</span><span class="o">+</span> <span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">size</span> <span class="o">+</span><span class="s">" rows"</span><span class="o">)</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition key is "</span> <span class="o">+</span> <span class="nf">sortSet</span><span class="o">(</span><span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nv">x</span><span class="o">.</span><span class="py">getInt</span><span class="o">(</span><span class="mi">3</span><span class="o">)).</span><span class="py">toSet</span><span class="o">))</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>partition0 has 954 rows
partition key is TreeSet(0, 2, 3)

partition1 has 1460 rows
partition key is TreeSet(5, 6, 8, 9)

partition2 has 730 rows
partition key is TreeSet(11, 12)

partition3 has 1460 rows
partition key is TreeSet(14, 15, 17, 18)

partition4 has 843 rows
partition key is TreeSet(20, 21, 23)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">RangePartitioner</code>는 <code class="language-plaintext highlighter-rouge">RDD</code>에 적용할 수 있기 때문에 위처럼 <code class="language-plaintext highlighter-rouge">DataFrame</code>을 <code class="language-plaintext highlighter-rouge">RDD</code>로 변환하여 적용해야합니다. <code class="language-plaintext highlighter-rouge">Dataset</code>은 <code class="language-plaintext highlighter-rouge">repartitionByRange</code>를 이용하여 적용할 수도 있습니다.<code class="language-plaintext highlighter-rouge">Hour</code> column에 해당하는 <code class="language-plaintext highlighter-rouge">x.getInt(3)</code> 을 기준으로  Range partition을 적용했습니다. 각 partition은 <code class="language-plaintext highlighter-rouge">0~3, 5~9, 11~12, 14~18, 20~23</code>의 5개 구간으로 나뉘어 구간에 해당하는 값들이 partition에 포함되었습니다.</p>

<h2 id="custom-partitioner">Custom Partitioner</h2>

<p>Hash, Range가 아닌 자신이 직접 규칙을 정의하여 reaprtition에 적용시킬 수도 있습니다. 저는 key를 <code class="language-plaintext highlighter-rouge">Day</code> 로 두고, 10으로 나눈 나머지를 partition 기준으로 결정하는 <code class="language-plaintext highlighter-rouge">CustomPartitioner</code>를 정의하고 적용해보겠습니다. 해당 데이터는 매일 같은 양이 수집된 데이터이므로,  <code class="language-plaintext highlighter-rouge">Day</code>에 이와 같은 규칙을 적용하면  rebalancing 효과도 나타날 것으로 기대됩니다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CustomPartitioner</span><span class="o">()</span> <span class="k">extends</span> <span class="nc">Partitioner</span> <span class="o">{</span>

        <span class="k">override</span> <span class="k">def</span> <span class="nf">numPartitions</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="k">override</span> <span class="k">def</span> <span class="nf">getPartition</span><span class="o">(</span><span class="n">key</span><span class="k">:</span> <span class="kt">Any</span><span class="o">)</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span>
          <span class="k">val</span> <span class="nv">code</span> <span class="k">=</span> <span class="nv">key</span><span class="o">.</span><span class="py">hashCode</span><span class="o">()</span> <span class="o">%</span> <span class="n">numPartitions</span>
          <span class="nf">if</span> <span class="o">(</span><span class="n">code</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">code</span> <span class="o">+</span> <span class="n">numPartitions</span>
          <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
            <span class="n">code</span>
          <span class="o">}</span>
        <span class="o">}</span>
  			<span class="k">override</span> <span class="k">def</span> <span class="nf">equals</span><span class="o">(</span><span class="n">other</span><span class="k">:</span> <span class="kt">scala.Any</span><span class="o">)</span><span class="k">:</span> <span class="kt">Boolean</span> <span class="o">=</span> <span class="n">other</span> <span class="k">match</span> <span class="o">{</span>
          <span class="k">case</span> <span class="n">custom</span><span class="k">:</span> <span class="kt">CustomPartitioner</span> <span class="o">=&gt;</span> <span class="nv">custom</span><span class="o">.</span><span class="py">numPartitions</span> <span class="o">==</span> <span class="n">numPartitions</span>
          <span class="k">case</span> <span class="k">_</span> <span class="k">=&gt;</span> <span class="kc">false</span>
        <span class="o">}</span>
      <span class="o">}</span>
<span class="c1">// https://m.blog.naver.com/syung1104/221103154997</span>

<span class="k">val</span> <span class="nv">dataRDD</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">getInt</span><span class="o">(</span><span class="mi">2</span><span class="o">),</span> <span class="nv">x</span><span class="o">.</span><span class="py">getDouble</span><span class="o">(</span><span class="mi">4</span><span class="o">)))</span> <span class="c1">// pairRDD</span>
<span class="k">val</span> <span class="nv">customedData</span> <span class="k">=</span> <span class="nv">dataRDD</span><span class="o">.</span><span class="py">partitionBy</span><span class="o">(</span><span class="k">new</span> <span class="nc">CustomPartitioner</span><span class="o">())</span>
<span class="k">val</span> <span class="nv">partitions</span> <span class="k">=</span> <span class="nv">customedData</span><span class="o">.</span><span class="py">glom</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="nf">for</span> <span class="o">(</span><span class="n">idx</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">to</span> <span class="mi">9</span><span class="o">)</span> <span class="o">{</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition"</span><span class="o">+</span><span class="n">idx</span><span class="o">+</span> <span class="s">" has "</span><span class="o">+</span> <span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">size</span> <span class="o">+</span><span class="s">" rows"</span><span class="o">)</span>
    <span class="nf">println</span><span class="o">(</span><span class="s">"partition key is "</span> <span class="o">+</span> <span class="nf">sortSet</span><span class="o">(</span><span class="nf">partitions</span><span class="o">(</span><span class="n">idx</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nv">x</span><span class="o">.</span><span class="py">_1</span><span class="o">).</span><span class="py">toSet</span><span class="o">))</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>partition0 has 523 rows
partition key is TreeSet(10, 20, 30)

partition1 has 641 rows
partition key is TreeSet(1, 11, 21, 31)

partition2 has 537 rows
partition key is TreeSet(2, 12, 22)

partition3 has 537 rows
partition key is TreeSet(3, 13, 23)

partition4 has 537 rows
partition key is TreeSet(4, 14, 24)

partition5 has 537 rows
partition key is TreeSet(5, 15, 25)

partition6 has 537 rows
partition key is TreeSet(6, 16, 26)

partition7 has 537 rows
partition key is TreeSet(7, 17, 27)

partition8 has 538 rows
partition key is TreeSet(8, 18, 28)

partition9 has 523 rows
partition key is TreeSet(9, 19, 29)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Day</code> 는 1~ 31까지 존재하고, 이들을 10으로 나눈 나머지(일의 자리)는 0~9까지 존재합니다. 따라서 10개 partition을 생성하였습니다. 위에서 살펴보았던 Hash, Range에 비해 reblancing이 꽤나 잘 되었습니다.</p>

<h2 id="rebalancing-is-not-guaranteed">Rebalancing is not guaranteed</h2>

<p>위 방법들을 적용했을 때 rebalancing이 항상 보장되는 것은 아닙니다. <code class="language-plaintext highlighter-rouge">repartition</code>을 사용하는 경우, 각 partition의 데이터 사이즈가 동일하도록 데이터를 셔플하지만,  hash, range, custom repartition은 규칙을 적용할 뿐 rebalancing을 고려하지 않습니다. 위를 비교해보면  hash, range를 적용했을 때는 partiton의 데이터 분포가 불균형합니다. 이에 비해 <code class="language-plaintext highlighter-rouge">Day</code>의 특성을 이용하여 <code class="language-plaintext highlighter-rouge">repartition</code>을 적용했기에 각 partition의 데이터 분포가 hash, range에 비해 균등합니다.</p>

<h1 id="sort-in-partition">Sort in Partition</h1>

<p>partition 내부를 정렬시킬 수도 있습니다. 예를 들어, 위의  Hash Partition을 적용한 결과 중 하나의 partition 내부를 살펴보겠습니다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">data_repartitioned</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">repartition</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">data_rdd</span> <span class="k">=</span> <span class="nv">data_repartitioned</span><span class="o">.</span><span class="py">rdd</span>
<span class="k">val</span> <span class="nv">partitions</span> <span class="k">=</span> <span class="nv">data_rdd</span><span class="o">.</span><span class="py">glom</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="nf">partitions</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">foreach</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Year, Month, Day, Hour, Pressure, WetTemp, DryTemp, Humidity, Direction, Speed, City]
[89,1,12,2,944.4,8.2,6.6,5,0,0,Canberra]
[89,1,12,5,945.8,7.9,6.3,4,0,0,Canberra]
[89,1,12,8,948.5,13.2,8.3,2,7,4,Canberra]
[89,1,12,11,948.3,18.1,11.5,5,16,4,Canberra]
[89,1,12,14,947.9,21.4,12.2,2,9,6,Canberra]
...
[89,1,13,2,953.2,14.1,12.4,11,0,0,Canberra]
[89,1,13,5,953.5,13.1,11.1,9,0,0,Canberra]
[89,1,13,8,954.9,15.6,11.8,8,6,5,Canberra]
[89,1,13,11,954.8,18.6,12.7,7,0,0,Canberra]
...
[89,12,18,5,1014.0,16.2,15.3,15,2,18,Gabo Island]
[89,12,18,8,1014.4,18.8,17.4,16,2,22,Gabo Island]
[89,12,18,11,1013.5,20.7,17.9,16,2,24,Gabo Island]
[89,12,18,14,1011.6,20.2,18.0,16,2,24,Gabo Island]
[89,12,18,17,1010.1,20.5,18.1,16,2,24,Gabo Island]
[89,12,18,20,1010.5,18.5,17.2,16,2,20,Gabo Island]

</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Day</code>가 <code class="language-plaintext highlighter-rouge">12, 13, 14, 18</code>인 Row들이 partition 내부에 존재하지만, 정렬되어있지는 않습니다. 이들을 <code class="language-plaintext highlighter-rouge">Day</code>, <code class="language-plaintext highlighter-rouge">Hour</code>를 기준으로 정렬해놓는다면 추후에 실행되는 작업들에서 실행 시간을 아낄 수 있을 것 같습니다. 이는 <code class="language-plaintext highlighter-rouge">sortWithinPartitions</code>를 통해 가능합니다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">data_repartitioned_sorted</span> <span class="k">=</span> <span class="nv">data_repartitioned</span><span class="o">.</span><span class="py">sortWithinPartitions</span><span class="o">(</span><span class="n">$</span><span class="s">"Day"</span><span class="o">,</span> <span class="n">$</span><span class="s">"Hour"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">data_rdd</span> <span class="k">=</span> <span class="nv">data_repartitioned_sorted</span><span class="o">.</span><span class="py">rdd</span>
<span class="k">val</span> <span class="nv">partitions</span> <span class="k">=</span> <span class="nv">data_rdd</span><span class="o">.</span><span class="py">glom</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="nf">partitions</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">foreach</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Year, Month, Day, Hour, Pressure, WetTemp, DryTemp, Humidity, Direction, Speed, City]
[89,4,12,0,945.5,11.1,10.0,9,0,0,Canberra]
[89,5,12,0,952.7,8.2,7.4,6,0,0,Canberra]
[89,6,12,0,948.8,7.4,6.0,4,9,6,Canberra]
[89,7,12,0,944.8,3.8,3.1,2,0,0,Canberra]
[89,8,12,0,957.7,2.0,0.5,-2,8,12,Canberra]
...
[89,1,18,23,942.6,16.0,14.5,13,0,0,Canberra]
[89,3,18,23,955.8,15.8,13.9,13,0,0,Canberra]
[89,11,18,23,945.9,12.3,11.5,11,4,2,Canberra]
[89,12,18,23,947.8,17.8,12.0,6,0,0,Canberra]
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Day</code>, <code class="language-plaintext highlighter-rouge">Hour</code>를 기준으로 partition 내부가 정렬되어 있음을 확인할 수 있습니다.</p>

<p><code class="language-plaintext highlighter-rouge">repartitionAndSortWithinPartitions</code>(<a href="https://spark.apache.org/docs/1.6.1/api/scala/index.html#org.apache.spark.rdd.OrderedRDDFunctions">link</a>)는 repartition과 sort를 동시에 적용해줍니다. piarRDD에서만 사용할 수 있습니다.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">dataRDD</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="nv">x</span><span class="o">.</span><span class="py">getInt</span><span class="o">(</span><span class="mi">2</span><span class="o">),</span> <span class="nv">x</span><span class="o">.</span><span class="py">getDouble</span><span class="o">(</span><span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="nv">dataRepartitionedSorted</span> <span class="k">=</span> <span class="nv">dataRDD</span><span class="o">.</span><span class="py">repartitionAndSortWithinPartitions</span><span class="o">(</span><span class="k">new</span> <span class="nc">HashPartitioner</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
</code></pre></div></div>

<p>[참고]</p>

<p><a href="https://m.blog.naver.com/syung1104/221103154997">[Spark] Apache Spark 사용해보기 - 7. Partitioning</a></p>

<p><a href="https://techvidvan.com/tutorials/spark-partition/">Apache Spark Partitioning and Spark Partition</a></p>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            <!-- 
                <section class="subscribe-form">
                    <h3 class="subscribe-form-title">Subscribe to Gyuhoon Kim</h3>
                    <p>Get the latest posts delivered right to your inbox</p>
                    <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>

                </section>
             -->

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/built/images/GyuhoonK.jpg" alt="GyuhoonK" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/GyuhoonK">GyuhoonK</a></h4>
                                
                                    <p>Read <a href="/author/GyuhoonK">more posts</a> by this author.</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/GyuhoonK">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            var this_page_url = 'https://gyuhoonk.github.io/spark-repartition';
                            var this_page_identifier = '/spark-repartition';
                            var this_page_title = 'repartition in Spark';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://xxxxxxxx.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/built/images/spain-blog-cover.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Gyuhoon Kim &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/hadoop/">Hadoop</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/parquet-ppd">Parquet and Predicate PushDown</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/spark-shuffle-partition">Partition, Spill in Spark</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/hadoop-distcp">hadoop distcp</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/hadoop/">
                                
                                    See all 8 posts  →
                                
                            </a>
                        </footer>
                    </article>
                <script type="text/javascript"
                src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
                </script>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Subtree">
                <div class="post-card-image" style="background-image: url(/assets/built/images/algorithm/subtree.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Subtree">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Algorithm</span>
                            
                        
                    

                    <h2 class="post-card-title">Softeer 거리 합 구하기</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Subtree를 이용한 거리 합 구하기

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/built/images/GyuhoonK.jpg" alt="GyuhoonK" />
                        
                        <span class="post-card-author">
                            <a href="/author/GyuhoonK/">GyuhoonK</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      4 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/sparkscala6">
                <div class="post-card-image" style="background-image: url(/assets/built/images/scala-banner-post.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/sparkscala6">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Scala</span>
                            
                        
                    

                    <h2 class="post-card-title">Learning Apache Spark 3 with Scala (Section6)</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Learning Apache Spark 3 with Scala (Section6 - Running Spark on Cluster)

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/built/images/GyuhoonK.jpg" alt="GyuhoonK" />
                        
                        <span class="post-card-author">
                            <a href="/author/GyuhoonK/">GyuhoonK</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      2 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="https://gyuhoonk.github.io/">
            
            <span>Gyuhoon Kim</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">repartition in Spark</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=repartition+in+Spark&amp;url=https://gyuhoonk.github.iospark-repartition"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://gyuhoonk.github.iospark-repartition"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://gyuhoonk.github.io/">Gyuhoon Kim</a> &copy; 2022</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                <h1 class="subscribe-overlay-title">Subscribe to Gyuhoon Kim</h1>
                <p class="subscribe-overlay-description">Stay up to date! Get all the latest &amp; greatest posts delivered straight to your inbox</p>
                <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>

            </div>
        </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-xxxxxxxx-x', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>
<script type="text/javascript" async
	src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	extensions: ["tex2jax.js"],
	jax: ["input/TeX", "output/HTML-CSS"],
	tex2jax: {
		inlineMath: [ ['$','$'], ["\\(","\\)"] ],
		displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
		processEscapes: true
	},
	"HTML-CSS": { availableFonts: ["TeX"] }
});
</script>
    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->
    <!-- math LaTex-->
    
</body>
</html>
